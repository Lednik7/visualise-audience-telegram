{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "visualise_audience_tg.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP1ul4mAkgzwHBuQFGkBK3Z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Lednik7/visualise-audience-telegram/blob/main/visualise_audience_tg.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dependency Upload"
      ],
      "metadata": {
        "id": "_FVnBMqukyIY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Package Download\n",
        "%%capture\n",
        "!pip install telethon\n",
        "!pip install transformers sentencepiece"
      ],
      "metadata": {
        "id": "gC7DRHouknHk",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Imports\n",
        "\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "from tqdm.notebook import tqdm\n",
        "from sklearn.decomposition import PCA, TruncatedSVD\n",
        "import pandas as pd\n",
        "import json\n",
        "from sklearn.cluster import DBSCAN, KMeans\n",
        "import altair as alt\n",
        "from IPython.display import clear_output"
      ],
      "metadata": {
        "id": "1FBJYkFqFoTB",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Default Settings\n",
        "#@markdown To gain access, go to the [website](https://my.telegram.org/auth?to=apps) and enter the relevant fields\n",
        "\n",
        "%%writefile run.py\n",
        "import configparser\n",
        "import json\n",
        "\n",
        "from telethon.tl.functions.users import GetFullUserRequest\n",
        "\n",
        "from telethon.sync import TelegramClient\n",
        "from telethon import connection\n",
        "from tqdm import tqdm\n",
        "\n",
        "# для корректного переноса времени сообщений в json\n",
        "from datetime import date, datetime\n",
        "\n",
        "# классы для работы с каналами\n",
        "from telethon.tl.functions.channels import GetParticipantsRequest\n",
        "from telethon.tl.types import ChannelParticipantsSearch\n",
        "\n",
        "# класс для работы с сообщениями\n",
        "from telethon.tl.functions.messages import GetHistoryRequest\n",
        "\n",
        "# Считываем учетные данные\n",
        "config = configparser.ConfigParser()\n",
        "config.read(\"config.ini\")\n",
        "\n",
        "# Присваиваем значения внутренним переменным\n",
        "api_id = 123 #@param {type:\"integer\"}\n",
        "api_hash = \"hash\" #@param {type:\"string\"}\n",
        "username = \"worker\"\n",
        "\n",
        "client = TelegramClient(username, api_id, api_hash)\n",
        "\n",
        "client.start()\n",
        "\n",
        "\n",
        "async def users_details(channel):\n",
        "    all_users_details = []  # список словарей с интересующими параметрами участников канала\n",
        "\n",
        "    pbar = tqdm()\n",
        "    async for participant in client.iter_participants(channel, aggressive=True):\n",
        "        full = await client(GetFullUserRequest(participant))\n",
        "        all_users_details.append({\"id\": participant.id,\n",
        "                                \"first_name\": participant.first_name,\n",
        "                                \"last_name\": participant.last_name,\n",
        "                                \"user\": participant.username,\n",
        "                                \"phone\": participant.phone,\n",
        "                                \"is_bot\": participant.bot,\n",
        "                                \"about\": full.about})\n",
        "        pbar.set_description(full.about)\n",
        "        pbar.update(1)\n",
        "\n",
        "    with open('channel_users.json', 'w', encoding='utf8') as outfile:\n",
        "        json.dump(all_users_details, outfile, ensure_ascii=False)\n",
        "\n",
        "\n",
        "async def main():\n",
        "    channel_link = \"https://t.me/gradientdip\" #@param {type:\"string\"}\n",
        "    channel = await client.get_entity(channel_link)\n",
        "    await users_details(channel)\n",
        "\n",
        "\n",
        "with client:\n",
        "    client.loop.run_until_complete(main())"
      ],
      "metadata": {
        "id": "gKB1KwJc7oHN",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python run.py\n",
        "clear_output()"
      ],
      "metadata": {
        "id": "G2dQMlDPlwCv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chart Generation"
      ],
      "metadata": {
        "id": "5ifw2HT3lfmi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Vector Representation\n",
        "\n",
        "with open(\"channel_users.json\", \"r\") as read_file:\n",
        "    channel_users = json.load(read_file)\n",
        "\n",
        "descriptions = [i[\"about\"] for i in channel_users if i[\"about\"]]\n",
        "\n",
        "%%capture\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"symanto/sn-xlm-roberta-base-snli-mnli-anli-xnli\")\n",
        "model = AutoModel.from_pretrained(\"symanto/sn-xlm-roberta-base-snli-mnli-anli-xnli\")\n",
        "\n",
        "\n",
        "def gen_batch(inputs, batch_size):\n",
        "    batch_start = 0\n",
        "    while batch_start < len(inputs):\n",
        "        yield inputs[batch_start: batch_start + batch_size]\n",
        "        batch_start += batch_size\n",
        "\n",
        "\n",
        "#Mean Pooling - Take attention mask into account for correct averaging\n",
        "def mean_pooling(text, model, tokenizer):\n",
        "    t = tokenizer(text, padding=True, truncation=True, return_tensors='pt')\n",
        "    with torch.no_grad():\n",
        "        model_output = model(**{k: v.to(model.device) for k, v in t.items()})\n",
        "    token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n",
        "    input_mask_expanded = t[\"attention_mask\"].unsqueeze(-1).expand(token_embeddings.size()).float()\n",
        "    return (torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)).cpu().numpy()\n",
        "\n",
        "\n",
        "batches = tuple(gen_batch(descriptions, batch_size=32))\n",
        "embeddings = []\n",
        "\n",
        "for batch in tqdm(batches):\n",
        "    embedding = mean_pooling(batch, model, tokenizer)\n",
        "    embeddings.extend(embedding)"
      ],
      "metadata": {
        "id": "wbbkw-mlncKZ",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Transform embeddings for 2D   \n",
        "\n",
        "def get_data_frame(n_clusters: int = 4) -> pd.DataFrame:\n",
        "    kmeans = KMeans(n_clusters=n_clusters,\n",
        "                    random_state=0).fit(transformed)\n",
        "\n",
        "    data = {\"y\": transformed[:, 0],\n",
        "            \"x\": transformed[:, 1],\n",
        "            \"description\": descriptions,\n",
        "            \"labels\": kmeans.labels_}\n",
        "\n",
        "    return pd.DataFrame(data)\n",
        "\n",
        "\n",
        "pca = PCA(n_components=2, random_state=42)\n",
        "transformed = pca.fit_transform(embeddings)"
      ],
      "metadata": {
        "id": "C_rA1H1MKxgJ",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Chart Settings\n",
        "\n",
        "n_clusters = 4 #@param {type:\"integer\"}\n",
        "mark_circle_size = 160 #@param {type:\"integer\"}\n",
        "width = 720 #@param {type:\"integer\"}\n",
        "height = 720 #@param {type:\"integer\"}\n",
        "\n",
        "df = get_data_frame(n_clusters=n_clusters)\n",
        "\n",
        "brush = alt.selection(type='interval', resolve='global')\n",
        "rng = ['red', 'green', 'black']\n",
        "\n",
        "alt.Chart(df).mark_circle(size=mark_circle_size).encode(\n",
        "    x='x', y='y', color=alt.Color('labels', scale=alt.Scale(range=rng)),\n",
        "    tooltip=['description']\n",
        ").add_selection(\n",
        "    brush\n",
        ").properties(\n",
        "    width=width,\n",
        "    height=height\n",
        ").interactive()"
      ],
      "metadata": {
        "id": "7iVEbT9pSOfN",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}